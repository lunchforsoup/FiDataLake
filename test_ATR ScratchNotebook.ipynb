{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from scipy.stats import gmean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "np.random.seed(42069)\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    'figure.figsize': (10, 5)\n",
    "     }\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This will download data from yahoo finance - more than enough for prototyping\n",
    "df = yf.download(\n",
    "        # tickers list or string as well\n",
    "        tickers = \"^tnx\",\n",
    "        # use \"period\" instead of start/end\n",
    "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "        # (optional, default is '1mo')\n",
    "        period = \"5y\",\n",
    "        # fetch data by interval (including intraday if period < 60 days)\n",
    "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "        # (optional, default is '1d')\n",
    "        interval = \"1d\",\n",
    "        # group by ticker (to access via data['SPY'])\n",
    "        # (optional, default is 'column')\n",
    "        group_by = 'ticker',\n",
    "        # adjust all OHLC automatically\n",
    "        # (optional, default is False)\n",
    "        auto_adjust = True,\n",
    "        # download pre/post regular market hours data\n",
    "        # (optional, default is False)\n",
    "        prepost = True,\n",
    "        # use threads for mass downloading? (True/False/Integer)\n",
    "        # (optional, default is True)\n",
    "        threads = True,\n",
    "        # proxy URL scheme use use when downloading?\n",
    "        # (optional, default is None)\n",
    "        proxy = None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Open   High    Low  Close  Volume\n",
      "Date                                          \n",
      "2017-02-13  2.436  2.452  2.427  2.434       0\n",
      "2017-02-14  2.441  2.502  2.431  2.470       0\n",
      "2017-02-15  2.484  2.524  2.483  2.502       0\n",
      "2017-02-16  2.475  2.492  2.438  2.450       0\n",
      "2017-02-17  2.406  2.429  2.400  2.425       0\n",
      "...           ...    ...    ...    ...     ...\n",
      "2022-02-07  1.921  1.939  1.910  1.916       0\n",
      "2022-02-08  1.943  1.971  1.943  1.954       0\n",
      "2022-02-09  1.936  1.947  1.909  1.929       0\n",
      "2022-02-10  1.929  2.050  1.927  2.031       0\n",
      "2022-02-11  2.007  2.063  1.934  1.955       0\n",
      "\n",
      "[1260 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_annotation(Data, name, onwhat, what_bull, what_bear, td, window = 50):\n",
    "    \n",
    "    Plottable = Data[-window:, ]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (10, 5))\n",
    "    ax.grid()\n",
    "    \n",
    "    ax.plot(Plottable[:, onwhat], color = 'black', linewidth = 1.5, label = name)\n",
    "    \n",
    "    for i in range(len(Plottable)):\n",
    "        \n",
    "        if Plottable[i, what_bull] < 0 and Plottable[i, what_bull] != -td:\n",
    "            \n",
    "            x = i\n",
    "            y = Plottable[i, onwhat]\n",
    "        \n",
    "            ax.annotate(int(Plottable[i, what_bull]), xy = (x, y), textcoords = \"offset points\", xytext = (0, - 10), ha = 'center',\n",
    "                        color = 'blue')\n",
    "            \n",
    "        elif Plottable[i, what_bull] == -td:\n",
    "            \n",
    "            x = i\n",
    "            y = Plottable[i, onwhat]\n",
    "        \n",
    "            ax.annotate(int(Plottable[i, what_bull]), xy = (x, y), textcoords = \"offset points\", xytext = (0, - 10), ha = 'center',\n",
    "                        color = 'red')\n",
    "            \n",
    "        elif Plottable[i, what_bear] > 0 and Plottable[i, what_bear] != td:\n",
    "            \n",
    "            x = i\n",
    "            y = Plottable[i, onwhat]\n",
    "        \n",
    "            ax.annotate(int(Plottable[i, what_bear]), xy = (x, y), textcoords = \"offset points\", xytext = (0, 10), ha = 'center',\n",
    "                        color = 'blue' )\n",
    "\n",
    "        elif Plottable[i, what_bear] == td:\n",
    "            \n",
    "            x = i\n",
    "            y = Plottable[i, onwhat]\n",
    "        \n",
    "            ax.annotate(int(Plottable[i, what_bear]), xy = (x, y), textcoords = \"offset points\", xytext = (0, 10), ha = 'center',\n",
    "                        color = 'red' )\n",
    "                     \n",
    "    ax.set_facecolor((0.95, 0.95, 0.95)) \n",
    "    plt.legend()\n",
    "    \n",
    "def adder(Data, times):\n",
    "    \n",
    "    for i in range(1, times + 1):\n",
    "    \n",
    "        new = np.zeros((len(Data), 1), dtype = float)\n",
    "        Data = np.append(Data, new, axis = 1)\n",
    "\n",
    "    return Data\n",
    "\n",
    "def deleter(Data, index, times):\n",
    "    \n",
    "    for i in range(1, times + 1):\n",
    "    \n",
    "        Data = np.delete(Data, index, axis = 1)\n",
    "\n",
    "    return Data\n",
    "   \n",
    "def jump(Data, jump):\n",
    "    \n",
    "    Data = Data[jump:, ]\n",
    "    \n",
    "    return Data\n",
    "\n",
    "def rounding(Data, how_far):\n",
    "    \n",
    "    Data = Data.round(decimals = how_far)\n",
    "    \n",
    "    return Data\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rolling_correlation(Data, first_data, second_data, lookback, where):\n",
    "    \n",
    "    # Adding an extra column\n",
    "    Data = adder(Data, 1)\n",
    "    \n",
    "    for i in range(len(Data)):\n",
    "        \n",
    "        try:\n",
    "            Data[i, where] = pearsonr(Data[i - lookback + 1:i + 1, first_data], Data[i - lookback + 1:i + 1, second_data])[0]\n",
    "            \n",
    "             \n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    Data = jump(Data, lookback) \n",
    "    \n",
    "    return Data\n",
    "\n",
    "def auto_correlation(Data, first_data, second_data, shift_degree, lookback, where):\n",
    "    \n",
    "    new_array = shift(Data[:, first_data], shift_degree, cval = 0)\n",
    "    new_array = np.reshape(new_array, (-1, 1))\n",
    "    \n",
    "    Data = np.concatenate((Data, new_array), axis = 1)\n",
    "    Data = adder(Data, 1)\n",
    "    \n",
    "    for i in range(len(Data)):\n",
    "        \n",
    "        try:\n",
    "            Data[i, where] = pearsonr(Data[i - lookback + 1:i + 1, first_data], Data[i - lookback + 1:i + 1, second_data])[0]\n",
    "            \n",
    "            \n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    Data = jump(Data, lookback) \n",
    "    Data = deleter(Data, where - 1, 1)\n",
    "    \n",
    "    return Data\n",
    "\n",
    "def volatility(Data, lookback, what, where):\n",
    "    \n",
    "    # Adding an extra column\n",
    "    Data = adder(Data, 1)\n",
    "    \n",
    "    for i in range(len(Data)):\n",
    "        \n",
    "        try:\n",
    "            Data[i, where] = (Data[i - lookback + 1:i + 1, what].std())\n",
    "    \n",
    "        except IndexError:\n",
    "            pass\n",
    "     \n",
    "    # Cleaning\n",
    "    Data = jump(Data, lookback)    \n",
    "     \n",
    "    return Data\n",
    "\n",
    "\n",
    "def ma(Data, lookback, close, where): \n",
    "    \n",
    "    Data = adder(Data, 1)\n",
    "    \n",
    "    for i in range(len(Data)):\n",
    "           \n",
    "            try:\n",
    "                Data[i, where] = (Data[i - lookback + 1:i + 1, close].mean())\n",
    "            \n",
    "            except IndexError:\n",
    "                pass\n",
    "            \n",
    "    # Cleaning\n",
    "    Data = jump(Data, lookback)\n",
    "    \n",
    "    return Data\n",
    "\n",
    "def ema(Data, alpha, lookback, what, where):\n",
    "    \n",
    "    alpha = alpha / (lookback + 1.0)\n",
    "    beta  = 1 - alpha\n",
    "    \n",
    "    # First value is a simple SMA\n",
    "    Data = ma(Data, lookback, what, where)\n",
    "    \n",
    "    # Calculating first EMA\n",
    "    Data[lookback + 1, where] = (Data[lookback + 1, what] * alpha) + (Data[lookback, where] * beta)\n",
    "\n",
    "    # Calculating the rest of EMA\n",
    "    for i in range(lookback + 2, len(Data)):\n",
    "            try:\n",
    "                Data[i, where] = (Data[i, what] * alpha) + (Data[i - 1, where] * beta)\n",
    "        \n",
    "            except IndexError:\n",
    "                pass\n",
    "            \n",
    "    return Data \n",
    "\n",
    "\n",
    "def atr(Data, lookback, high, low, close, where, genre = 'Smoothed'):\n",
    "    \n",
    "    # Adding the required columns\n",
    "    Data = adder(Data, 1)\n",
    "    \n",
    "    # True Range Calculation\n",
    "    for i in range(len(Data)):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            Data[i, where] =   max(Data[i, high] - Data[i, low],\n",
    "                               abs(Data[i, high] - Data[i - 1, close]),\n",
    "                               abs(Data[i, low] - Data[i - 1, close]))\n",
    "            \n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "    Data[0, where] = 0   \n",
    "    \n",
    "    if genre == 'Smoothed':\n",
    "        \n",
    "        # Average True Range Calculation\n",
    "        Data = ema(Data, 2, lookback, where, where + 1)\n",
    "    \n",
    "    if genre == 'Simple':\n",
    "    \n",
    "        # Average True Range Calculation\n",
    "        Data = ma(Data, lookback, where, where + 1)\n",
    "    \n",
    "    # Cleaning\n",
    "    Data = deleter(Data, where, 1)\n",
    "    Data = jump(Data, lookback)\n",
    "\n",
    "    return Data\n",
    "\n",
    "def Synatr(Data,  high, low, close, where, genre = 'Smoothed'):\n",
    "    \n",
    "    # Adding the required columns\n",
    "    Data = adder(Data, 1)\n",
    "    \n",
    "    lookback =2 \n",
    "    \n",
    "    # True Range Calculation\n",
    "    for i in range(len(Data)):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            Data[i, where] =   max(Data[i, high] - Data[i, low],\n",
    "                               abs(Data[i, high] - Data[i - 1, close]),\n",
    "                               abs(Data[i, low] - Data[i - 1, close]))\n",
    "            \n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "    Data[0, where] = 0   \n",
    "    \n",
    "    if genre == 'Smoothed':\n",
    "        \n",
    "        # Average True Range Calculation\n",
    "        Data = ema(Data, 2, lookback, where, where + 1)\n",
    "    \n",
    "    if genre == 'Simple':\n",
    "    \n",
    "        # Average True Range Calculation\n",
    "        Data = np.divide(ma(Data, 2, where, where + 1),ma(Data, 1, where, where + 1))\n",
    "    \n",
    "    # Cleaning\n",
    "    Data = deleter(Data, where, 1)\n",
    "    Data = jump(Data, lookback)\n",
    "\n",
    "    return Data\n",
    "\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=atr(df,2,1,2,3,5,'Simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=atr(my_data,1,1,2,3,6,'Simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1251,9) (1252,9) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5ee489ea7656>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSynatr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Simple'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-ddfbcffaaa10>\u001b[0m in \u001b[0;36mSynatr\u001b[1;34m(Data, high, low, close, where, genre)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;31m# Average True Range Calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;31m# Cleaning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1251,9) (1252,9) "
     ]
    }
   ],
   "source": [
    "my_data=Synatr(my_data,1,2,3,7,'Simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-18</th>\n",
       "      <td>195.615868</td>\n",
       "      <td>195.679776</td>\n",
       "      <td>194.730190</td>\n",
       "      <td>195.131943</td>\n",
       "      <td>76869700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-19</th>\n",
       "      <td>195.414981</td>\n",
       "      <td>195.981080</td>\n",
       "      <td>195.031494</td>\n",
       "      <td>195.652374</td>\n",
       "      <td>66519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-20</th>\n",
       "      <td>195.277985</td>\n",
       "      <td>195.880614</td>\n",
       "      <td>194.584058</td>\n",
       "      <td>195.287125</td>\n",
       "      <td>73639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-21</th>\n",
       "      <td>195.287150</td>\n",
       "      <td>195.469761</td>\n",
       "      <td>194.264503</td>\n",
       "      <td>195.378448</td>\n",
       "      <td>89089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-24</th>\n",
       "      <td>196.309773</td>\n",
       "      <td>196.601962</td>\n",
       "      <td>195.834974</td>\n",
       "      <td>196.209335</td>\n",
       "      <td>60146600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close    Volume\n",
       "Date                                                                \n",
       "2016-10-18  195.615868  195.679776  194.730190  195.131943  76869700\n",
       "2016-10-19  195.414981  195.981080  195.031494  195.652374  66519200\n",
       "2016-10-20  195.277985  195.880614  194.584058  195.287125  73639800\n",
       "2016-10-21  195.287150  195.469761  194.264503  195.378448  89089100\n",
       "2016-10-24  196.309773  196.601962  195.834974  196.209335  60146600"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[194.675392 195.780197 194.419720 ... 75705500.000000 1.136773 1.360477]\n",
      " [195.926316 195.962833 194.556713 ... 77220200.000000 1.383299 1.406120]\n",
      " [194.611461 195.332779 193.305779 ... 140623200.000000 1.716560 2.027000]\n",
      " ...\n",
      " [439.079987 442.660004 438.579987 ... 70236800.000000 5.994995 7.480011]\n",
      " [444.750000 446.260010 444.089996 ... 66226800.000000 5.620010 3.760010]\n",
      " [443.970001 447.019989 443.269989 ... 33588065.000000 3.755005 3.750000]]\n"
     ]
    }
   ],
   "source": [
    "print(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'isna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1b7d9adcdc93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnullvaluecheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmy_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'missing %'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnullvaluecheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackground_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'PuBu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'isna'"
     ]
    }
   ],
   "source": [
    "nullvaluecheck = pd.DataFrame(my_data.isna().sum().sort_values(ascending=False)*100/my_data.shape[0],columns=['missing %']).head(60)\n",
    "nullvaluecheck.style.background_gradient(cmap='PuBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
